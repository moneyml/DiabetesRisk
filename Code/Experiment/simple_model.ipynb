{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 只做单模型，其他的内容，等等再说，现在把单模型的表现提升上去再说吧\n",
    "### 测试看下来，单纯得跑模型似乎会应该Y值的方差而产生巨大问题，我们需要重新做一次分类，明天的核心任务吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "\n",
    "import model_ml as mm\n",
    "import feat_engineering as fe\n",
    "import feat_selection as fs\n",
    "from param_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(config.original_train_data_path)\n",
    "dfPred = pd.read_csv(config.original_pred_data_path)\n",
    "predictors = dfPred.columns.tolist()[4:]\n",
    "check_missing = ['PartI_1','PartII_1','PartIII_1','PartIV_1','PartV_1','PartVI_1']\n",
    "\n",
    "\n",
    "###清理异常Y值\n",
    "dfTrain = dfTrain.loc[dfTrain['Y']<dfTrain['Y'].max()]\n",
    "dfTrain = dfTrain.reset_index(drop=True)\n",
    "\n",
    "dfTrain = dfTrain.loc[dfTrain['Y']>dfTrain['Y'].quantile(0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeatAll(train,pred):\n",
    "    dfAll = pd.concat([train,pred])\n",
    "    dfAll = dfAll.reset_index(drop=True)\n",
    "    dfAll['date'] = (pd.to_datetime(dfAll['date']) - parse('2017-10-09')).dt.days\n",
    "\n",
    "    ###这个部分将每一列分箱，并且计算基于该列分类的其他列的百分比顺序，目前看来没啥用\n",
    "    var_dict = {}\n",
    "    for colBase in predictors+['sex','age']:\n",
    "        if dfAll[colBase].nunique()<=5:\n",
    "            var_dict[colBase] = [x for x in predictors if x!=colBase]\n",
    "        else:\n",
    "            dfAll[colBase+'_based'] = pd.cut(dfAll[colBase],bins=5,labels=[colBase+'_bin_%d'%i for i in range(5)])\n",
    "            dfAll[colBase+'_based'] = dfAll[colBase+'_based'].astype(str)\n",
    "            dfAll[colBase+'_based'].fillna(colBase+'_bin_NA',inplace = True)\n",
    "            var_dict[colBase+'_based'] = [x for x in predictors if x!=colBase]\n",
    "    #dfAllPcentByOther = fe.pcent_by_other_col(dfAll,var_dict,['ID']) \n",
    "    #dfAllPcentByOther = pd.read_csv('../../Cache/pcent_by_other.csv')\n",
    "    \n",
    "    for var in dfAll.columns:\n",
    "        if '_based' in var:\n",
    "            del dfAll[var]\n",
    "            \n",
    "    ###根据日期放置一个百分比顺序作为尝试\n",
    "    dfAllPcentByDate = fe.pcent_by_other_col(dfAll,{'date':predictors},['ID']) \n",
    "    \n",
    "    '''dfAll['date'] = pd.qcut(dfAll['date'],q=10,labels=['date_bin_%d'%i for i in range(10)])\n",
    "    dfAll = pd.concat([dfAll,pd.get_dummies(dfAll['date'])],axis=1)'''\n",
    "    ###目前不想使用日期，觉得用处不大\n",
    "    del dfAll['date']\n",
    "\n",
    "    #for minus in \n",
    "    \n",
    "    for ratio in [['PartI_6','PartI_5'],['PartI_7','PartI_5'],['PartII_3','PartII_2'],['PartII_4','PartII_2'],['PartV_2','PartV_1'],['PartII_1','PartII_2']]:\n",
    "        dfAll[ratio[0]+'_divided_'+ratio[1]] = dfAll[ratio[0]]/dfAll[ratio[1]]\n",
    "        \n",
    "    for multiply in [['PartV_1','PartV_9'],['PartV_1','PartV_10'],['PartV_1','PartV_11'],['PartV_1','PartV_12'],['PartV_1','PartV_13']]:\n",
    "        dfAll[multiply[0]+'_multiply_'+multiply[1]] = dfAll[multiply[0]]/dfAll[multiply[1]]\n",
    "    \n",
    "    \n",
    "    ###看看missing 的情况\n",
    "    dfAll['missing_cnt'] = dfAll[check_missing].isnull().sum(axis=1)\n",
    "    for i in range(len(check_missing)):\n",
    "        dfAll['missing_part%d'%i] = dfAll[check_missing[i]].isnull().astype(int)\n",
    "    \n",
    "    \n",
    "    '''for key,group in {'PartI':['PartI_1','PartI_2','PartI_3','PartI_4'],'PartII':['PartII_1','PartII_3','PartII_4']}.items():\n",
    "        dfAll['group_'+key+'_std'] = dfAll[group].std(axis=1)\n",
    "        dfAll['group_'+key+'_mean'] = dfAll[group].mean(axis=1)\n",
    "        dfAll['group_'+key+'_median'] = dfAll[group].median(axis=1)'''\n",
    "    \n",
    "    #dfAll = dfAll.merge(dfAllPcentByOther,'inner','ID')\n",
    "    dfAll = dfAll.merge(dfAllPcentByDate,'inner','ID')\n",
    "    \n",
    "    \n",
    "    dfTrain = dfAll.loc[dfAll['ID'].isin(train['ID'])]\n",
    "    dfPred = dfAll.loc[dfAll['ID'].isin(pred['ID'])]\n",
    "    \n",
    "    return dfTrain,dfPred,var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "dfTrain,dfPred,var_dict = FeatAll(dfTrain,dfPred)\n",
    "predictors = dfPred.columns.tolist()\n",
    "predictors.remove('ID')\n",
    "predictors.remove('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"keep = ['ID']\\nfor var in predictors:\\n    if 'pcent' in var and '_y' not in var:\\n        print(var)\\n        keep.append(var)\\nkeep\\ndfAll = pd.concat([dfTrain[keep],dfPred[keep]])\\nrename_dict = {}\\nfor var in keep:\\n    if '_x' in var:\\n        rename_dict[var] = var[0:-2]\\ndfAll = dfAll.rename(columns=rename_dict)\\ndfAll.to_csv('../../Cache/pcent_by_other.csv',index = False)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''keep = ['ID']\n",
    "for var in predictors:\n",
    "    if 'pcent' in var and '_y' not in var:\n",
    "        print(var)\n",
    "        keep.append(var)\n",
    "keep\n",
    "dfAll = pd.concat([dfTrain[keep],dfPred[keep]])\n",
    "rename_dict = {}\n",
    "for var in keep:\n",
    "    if '_x' in var:\n",
    "        rename_dict[var] = var[0:-2]\n",
    "dfAll = dfAll.rename(columns=rename_dict)\n",
    "dfAll.to_csv('../../Cache/pcent_by_other.csv',index = False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.8561\teval-rmse:8.71965\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.87061\teval-rmse:3.97918\n",
      "[200]\ttrain-rmse:2.28375\teval-rmse:2.8346\n",
      "[300]\ttrain-rmse:1.79374\teval-rmse:2.67881\n",
      "Stopping. Best iteration:\n",
      "[326]\ttrain-rmse:1.72219\teval-rmse:2.67673\n",
      "\n",
      "Best tree is 327, performance is 1.722187, 2.676727\n",
      "[0]\ttrain-rmse:8.69484\teval-rmse:9.35785\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.80603\teval-rmse:4.65414\n",
      "[200]\ttrain-rmse:2.26043\teval-rmse:3.30007\n",
      "[300]\ttrain-rmse:1.79767\teval-rmse:2.9558\n",
      "[400]\ttrain-rmse:1.5842\teval-rmse:2.86137\n",
      "[500]\ttrain-rmse:1.44296\teval-rmse:2.8239\n",
      "[600]\ttrain-rmse:1.32429\teval-rmse:2.8085\n",
      "Stopping. Best iteration:\n",
      "[613]\ttrain-rmse:1.31102\teval-rmse:2.80586\n",
      "\n",
      "Best tree is 614, performance is 1.311023, 2.805860\n",
      "[0]\ttrain-rmse:8.75882\teval-rmse:9.11317\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.83126\teval-rmse:4.52145\n",
      "[200]\ttrain-rmse:2.27038\teval-rmse:3.26523\n",
      "[300]\ttrain-rmse:1.79483\teval-rmse:2.99015\n",
      "[400]\ttrain-rmse:1.58618\teval-rmse:2.91846\n",
      "[500]\ttrain-rmse:1.44488\teval-rmse:2.89497\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-rmse:1.44658\teval-rmse:2.89446\n",
      "\n",
      "Best tree is 500, performance is 1.446576, 2.894464\n",
      "[0]\ttrain-rmse:9.00007\teval-rmse:8.10272\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:4.006\teval-rmse:3.06953\n",
      "[200]\ttrain-rmse:2.39459\teval-rmse:1.76995\n",
      "Stopping. Best iteration:\n",
      "[270]\ttrain-rmse:2.00016\teval-rmse:1.68656\n",
      "\n",
      "Best tree is 271, performance is 2.000158, 1.686555\n",
      "[0]\ttrain-rmse:8.8352\teval-rmse:8.80965\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.87795\teval-rmse:4.11669\n",
      "[200]\ttrain-rmse:2.28234\teval-rmse:2.89808\n",
      "[300]\ttrain-rmse:1.7841\teval-rmse:2.67585\n",
      "Stopping. Best iteration:\n",
      "[341]\ttrain-rmse:1.68106\teval-rmse:2.65649\n",
      "\n",
      "Best tree is 342, performance is 1.681059, 2.656492\n",
      "Test MSE: 6.6664812383\n"
     ]
    }
   ],
   "source": [
    "n_splits=5\n",
    "test_result,result,imp = mm.xgb_kfold(dfTrain,dfPred,predictors,n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,n_splits+1):\n",
    "    imp['imp_fold%d'%i] = imp['imp_fold%d'%i]/imp['imp_fold%d'%i].sum()\n",
    "imp['sum_imp'] = imp[['imp_fold%d'%i for i in range(1,n_splits+1)]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp.sort_values('sum_imp',ascending=False)\n",
    "tmpPredictor = imp.sort_values('sum_imp',ascending=False)['variable'].values.tolist()[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.85632\teval-rmse:8.71935\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.88836\teval-rmse:3.98554\n",
      "[200]\ttrain-rmse:2.29915\teval-rmse:2.82965\n",
      "[300]\ttrain-rmse:1.80459\teval-rmse:2.65936\n",
      "Stopping. Best iteration:\n",
      "[303]\ttrain-rmse:1.79739\teval-rmse:2.65732\n",
      "\n",
      "Best tree is 304, performance is 1.797392, 2.657317\n",
      "[0]\ttrain-rmse:8.69484\teval-rmse:9.35785\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.81414\teval-rmse:4.66087\n",
      "[200]\ttrain-rmse:2.27655\teval-rmse:3.30779\n",
      "[300]\ttrain-rmse:1.81251\teval-rmse:2.95693\n",
      "[400]\ttrain-rmse:1.60783\teval-rmse:2.85228\n",
      "[500]\ttrain-rmse:1.47348\teval-rmse:2.81145\n",
      "Stopping. Best iteration:\n",
      "[549]\ttrain-rmse:1.41809\teval-rmse:2.8001\n",
      "\n",
      "Best tree is 550, performance is 1.418090, 2.800099\n",
      "[0]\ttrain-rmse:8.75882\teval-rmse:9.11317\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.83582\teval-rmse:4.52908\n",
      "[200]\ttrain-rmse:2.28729\teval-rmse:3.25957\n",
      "[300]\ttrain-rmse:1.81938\teval-rmse:2.96369\n",
      "[400]\ttrain-rmse:1.61379\teval-rmse:2.89165\n",
      "[500]\ttrain-rmse:1.47903\teval-rmse:2.85662\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-rmse:1.48081\teval-rmse:2.85605\n",
      "\n",
      "Best tree is 500, performance is 1.480814, 2.856054\n",
      "[0]\ttrain-rmse:9.00029\teval-rmse:8.1025\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:4.00702\teval-rmse:3.06861\n",
      "[200]\ttrain-rmse:2.42904\teval-rmse:1.77433\n",
      "Stopping. Best iteration:\n",
      "[251]\ttrain-rmse:2.11532\teval-rmse:1.70308\n",
      "\n",
      "Best tree is 252, performance is 2.115316, 1.703083\n",
      "[0]\ttrain-rmse:8.83534\teval-rmse:8.80945\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:3.88506\teval-rmse:4.12103\n",
      "[200]\ttrain-rmse:2.30011\teval-rmse:2.89615\n",
      "[300]\ttrain-rmse:1.81564\teval-rmse:2.65294\n",
      "[400]\ttrain-rmse:1.60642\teval-rmse:2.61222\n",
      "Stopping. Best iteration:\n",
      "[454]\ttrain-rmse:1.52315\teval-rmse:2.60473\n",
      "\n",
      "Best tree is 455, performance is 1.523154, 2.604733\n",
      "Test MSE: 6.55205184435\n"
     ]
    }
   ],
   "source": [
    "test_result,result,imp = mm.xgb_kfold(dfTrain,dfPred,tmpPredictor,n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "other_note ='_sick_test'\n",
    "result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "submit = result[['ID','score']]\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "result.to_csv('../../Submission/result/result_%s'%today+other_note+'.csv',index=False)\n",
    "submit['score'].to_csv('../../Submission/submit_%s'%today+other_note+'.csv',header=False,index=False)\n",
    "test_result.to_csv('../../Submission/test/test_result_%s'%today+other_note+'.csv',index=False)\n",
    "imp.to_csv('../../Submission/imp/importance_%s'%today+other_note+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###基础变量\n",
    "1.83977998784\n",
    "\n",
    "###增加部分比例数据，已经缺失体检项目情况\n",
    "1.84295123211  imp来看，missing信息没有意义\n",
    "\n",
    "###上一版去除missing\n",
    "1.83839589522\n",
    "\n",
    "\n",
    "\n",
    "###增加一些比值信息\n",
    "1.84354856365\n",
    "\n",
    "\n",
    "###根据日期的百分比，效果更加不好了\n",
    "1.85046680299  变量选择之后 1.83862284729\n",
    "\n",
    "\n",
    "###前面所有的特征\n",
    "1.86013896413   变量选择之后  1.85446185976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
